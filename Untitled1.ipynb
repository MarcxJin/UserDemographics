{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand features: train shape (74645, 131), test shape (112071, 131)\n",
      "Model features: train shape (74645, 1667), test shape (112071, 1667)\n",
      "Apps data: train shape (74645, 19237), test shape (112071, 19237)\n",
      "Labels data: train shape (74645, 492), test shape (112071, 492)\n",
      "time data: train shape (74645, 55), test shape (112071, 55)\n",
      "location data: train shape (74645, 690), test shape (112071, 690)\n",
      "All features: train shape (74645, 22272), test shape (112071, 22272)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import os\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "# load dataset\n",
    "\n",
    "datadir = 'Desktop/talkingdata'\n",
    "\n",
    "gatrain = pd.read_csv(os.path.join(datadir,'gender_age_train.csv'), index_col='device_id')\n",
    "gatest = pd.read_csv(os.path.join(datadir,'gender_age_test.csv'), index_col = 'device_id')\n",
    "phone = pd.read_csv(os.path.join(datadir,'phone_brand_device_model.csv'))\n",
    "# Get rid of duplicate device ids in phone\n",
    "phone = phone.drop_duplicates('device_id',keep='first').set_index('device_id')\n",
    "events = pd.read_csv(os.path.join(datadir,'events.csv'),  parse_dates=['timestamp'], index_col='event_id')\n",
    "appevents = pd.read_csv(os.path.join(datadir,'app_events.csv'), usecols=['event_id','app_id','is_active'], dtype={'is_active':bool})\n",
    "applabels = pd.read_csv(os.path.join(datadir,'app_labels.csv'))\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "# phone brand\n",
    "gatrain['trainrow'] = np.arange(gatrain.shape[0])\n",
    "gatest['testrow'] = np.arange(gatest.shape[0])\n",
    "brandencoder = LabelEncoder().fit(phone.phone_brand)\n",
    "phone['brand'] = brandencoder.transform(phone['phone_brand'])\n",
    "gatrain['brand'] = phone['brand']\n",
    "gatest['brand'] = phone['brand']\n",
    "Xtr_brand = csr_matrix((np.ones(gatrain.shape[0]),\n",
    "                       (gatrain.trainrow, gatrain.brand)))\n",
    "Xte_brand = csr_matrix((np.ones(gatest.shape[0]),\n",
    "                       (gatest.testrow, gatest.brand)))\n",
    "print('Brand features: train shape {}, test shape {}'.format(Xtr_brand.shape, Xte_brand.shape))\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "# phone model\n",
    "m = phone.phone_brand.str.cat(phone.device_model)\n",
    "\n",
    "modelencoder = LabelEncoder().fit(m)\n",
    "phone['model'] = modelencoder.transform(m)\n",
    "gatrain['model'] = phone['model']\n",
    "gatest['model'] = phone['model']\n",
    "Xtr_model = csr_matrix((np.ones(gatrain.shape[0]),\n",
    "                       (gatrain.trainrow, gatrain.model)))\n",
    "Xte_model = csr_matrix((np.ones(gatest.shape[0]),\n",
    "                       (gatest.testrow, gatest.model)))\n",
    "print('Model features: train shape {}, test shape {}'.format(Xtr_model.shape, Xte_model.shape))\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "# apps installed\n",
    "appencoder = LabelEncoder().fit(appevents.app_id)\n",
    "appevents['app'] = appencoder.transform(appevents.app_id)\n",
    "napps = len(appencoder.classes_)\n",
    "deviceapps = (appevents.merge(events[['device_id']], how='left',left_on='event_id',right_index=True)\n",
    "                       .groupby(['device_id','app'])['app'].agg(['size'])\n",
    "                       .merge(gatrain[['trainrow']], how='left', left_index=True, right_index=True)\n",
    "                       .merge(gatest[['testrow']], how='left', left_index=True, right_index=True)\n",
    "                       .reset_index())\n",
    "deviceapps.head()\n",
    "\n",
    "d = deviceapps.dropna(subset=['trainrow'])\n",
    "Xtr_app = csr_matrix((np.ones(d.shape[0]), (d.trainrow, d.app)),\n",
    "                      shape=(gatrain.shape[0],napps))\n",
    "d = deviceapps.dropna(subset=['testrow'])\n",
    "Xte_app = csr_matrix((np.ones(d.shape[0]), (d.testrow, d.app)),\n",
    "                      shape=(gatest.shape[0],napps))\n",
    "print('Apps data: train shape {}, test shape {}'.format(Xtr_app.shape, Xte_app.shape))\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "# labels\n",
    "applabels = applabels.loc[applabels.app_id.isin(appevents.app_id.unique())]\n",
    "applabels['app'] = appencoder.transform(applabels.app_id)\n",
    "labelencoder = LabelEncoder().fit(applabels.label_id)\n",
    "applabels['label'] = labelencoder.transform(applabels.label_id)\n",
    "nlabels = len(labelencoder.classes_)\n",
    "\n",
    "devicelabels = (deviceapps[['device_id','app']]\n",
    "                .merge(applabels[['app','label']])\n",
    "                .groupby(['device_id','label'])['app'].agg(['size'])\n",
    "                .merge(gatrain[['trainrow']], how='left', left_index=True, right_index=True)\n",
    "                .merge(gatest[['testrow']], how='left', left_index=True, right_index=True)\n",
    "                .reset_index())\n",
    "devicelabels.head()\n",
    "\n",
    "d = devicelabels.dropna(subset=['trainrow'])\n",
    "Xtr_label = csr_matrix((np.ones(d.shape[0]), (d.trainrow, d.label)),\n",
    "                      shape=(gatrain.shape[0],nlabels))\n",
    "d = devicelabels.dropna(subset=['testrow'])\n",
    "Xte_label = csr_matrix((np.ones(d.shape[0]), (d.testrow, d.label)),\n",
    "                      shape=(gatest.shape[0],nlabels))\n",
    "print('Labels data: train shape {}, test shape {}'.format(Xtr_label.shape, Xte_label.shape))\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "# time\n",
    "time=pd.read_csv('Desktop/talkingdata/time.csv')\n",
    "ntime = 55\n",
    "\n",
    "d = time.dropna(subset=['trainrow'])\n",
    "Xtr_time = csr_matrix((np.ones(d.shape[0]), (d.trainrow, d.time)), \n",
    "                      shape=(gatrain.shape[0],ntime))\n",
    "d = time.dropna(subset=['testrow'])\n",
    "Xte_time = csr_matrix((np.ones(d.shape[0]) , (d.testrow, d.time)), \n",
    "                      shape=(gatest.shape[0],ntime))\n",
    "print('time data: train shape {}, test shape {}'.format(Xtr_time.shape, Xte_time.shape))\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "# location\n",
    "zipcode=pd.read_csv('Desktop/talkingdata/zipcode.csv')\n",
    "nzips=690\n",
    "\n",
    "d = zipcode.dropna(subset=['trainrow'])\n",
    "Xtr_location = csr_matrix((np.ones(d.shape[0]), (d.trainrow, d['zip'])), \n",
    "                      shape=(gatrain.shape[0],nzips))\n",
    "d = zipcode.dropna(subset=['testrow'])\n",
    "Xte_location = csr_matrix((np.ones(d.shape[0]) , (d.testrow, d['zip'])), \n",
    "                      shape=(gatest.shape[0],nzips))\n",
    "print('location data: train shape {}, test shape {}'.format(Xtr_location.shape, Xte_location.shape))\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "Xtrain = hstack((Xtr_brand, Xtr_model, Xtr_app, Xtr_label, Xtr_time, Xtr_location), format='csr')\n",
    "Xtest =  hstack((Xte_brand, Xte_model, Xte_app, Xte_label, Xte_time, Xte_location), format='csr')\n",
    "print('All features: train shape {}, test shape {}'.format(Xtrain.shape, Xtest.shape))\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "targetencoder = LabelEncoder().fit(gatrain.group)\n",
    "y = targetencoder.transform(gatrain.group)\n",
    "nclasses = len(targetencoder.classes_)\n",
    "dummy_y = np_utils.to_categorical(y) ## Funcion de Keras!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 'mle')\n",
    "Xtrain_new = pca.fit_transform(Xtrain.toarray())\n",
    "Xtest_new = pca.fit_transform(Xtest.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[12]:\n",
    "\n",
    "def batch_generator(X, y, batch_size, shuffle):\n",
    "    #chenglong code for fiting from generator (https://www.kaggle.com/c/talkingdata-mobile-user-demographics/forums/t/22567/neural-network-for-sparse-matrices)\n",
    "    number_of_batches = np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[batch_index,:].toarray()\n",
    "        y_batch = y[batch_index]\n",
    "        counter += 1\n",
    "        yield X_batch, y_batch\n",
    "        if (counter == number_of_batches):\n",
    "            if shuffle:\n",
    "                np.random.shuffle(sample_index)\n",
    "            counter = 0\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "def batch_generatorp(X, batch_size, shuffle):\n",
    "    number_of_batches =X.shape[0] /  np.ceil(X.shape[0]/batch_size)\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n",
    "        X_batch = X[batch_index, :].toarray()\n",
    "        counter += 1\n",
    "        yield X_batch\n",
    "        if (counter == number_of_batches):\n",
    "            counter = 0\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "# build model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(150, input_dim=Xtrain_new.shape[1], init='normal'))\n",
    "    model.add(PReLU())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(50, input_dim=Xtrain_new.shape[1], init='normal'))\n",
    "    model.add(PReLU())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(12, init='normal', activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])  #logloss\n",
    "    return model\n",
    "\n",
    "model=baseline_model()\n",
    "X_train, X_val, y_train, y_val = train_test_split(Xtrain_new, dummy_y, test_size=0.02, random_state=42)\n",
    "fit= model.fit_generator(generator=batch_generator(X_train, y_train, 400, True),\n",
    "                         nb_epoch=15,\n",
    "                         samples_per_epoch=69984,\n",
    "                         validation_data=(X_val.todense(), y_val), verbose=2\n",
    "                         )\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "# evaluate the model\n",
    "scores_val = model.predict_generator(generator=batch_generatorp(X_val, 400, False), val_samples=X_val.shape[0])\n",
    "print('logloss val {}'.format(log_loss(y_val, scores_val)))\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "print(\"# Final prediction\")\n",
    "scores = model.predict_generator(generator=batch_generatorp(Xtest_new, 800, False), val_samples=Xtest.shape[0])\n",
    "pred = pd.DataFrame(scores, index = gatest.index, columns=targetencoder.classes_)\n",
    "pred.to_csv('submit21.csv',index=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
